#!/usr/bin/env python
# coding: utf-8

# # **Course 3 Automatidata project**
# **Course 3 - Go Beyond the Numbers: Translate Data into Insights**

# You are the newest data professional in a fictional data consulting firm: Automatidata. The team is still early into the project, having only just completed an initial plan of action and some early Python coding work. 
# 
# Luana Rodriquez, the senior data analyst at Automatidata, is pleased with the work you have already completed and requests your assistance with some EDA and data visualization work for the New York City Taxi and Limousine Commission project (New York City TLC) to get a general understanding of what taxi ridership looks like. The management team is asking for a Python notebook showing data structuring and cleaning, as well as any matplotlib/seaborn visualizations plotted to help understand the data. At the very least, include a box plot of the ride durations and some time series plots, like a breakdown by quarter or month. 
# 
# Additionally, the management team has recently asked all EDA to include Tableau visualizations. For this taxi data, create a Tableau dashboard showing a New York City map of taxi/limo trips by month. Make sure it is easy to understand to someone who isn’t data savvy, and remember that the assistant director at the New York City TLC is a person with visual impairments.
# 
# A notebook was structured and prepared to help you in this project. Please complete the following questions.

# # Course 3 End-of-course project: Exploratory data analysis
# 
# In this activity, you will examine data provided and prepare it for analysis. You will also design a professional data visualization that tells a story, and will help data-driven decisions for business needs. 
# 
# Please note that the Tableau visualization activity is optional, and will not affect your completion of the course. Completing the Tableau activity will help you practice planning out and plotting a data visualization based on a specific business need. The structure of this activity is designed to emulate the proposals you will likely be assigned in your career as a data professional. Completing this activity will help prepare you for those career moments.
# 
# **The purpose** of this project is to conduct exploratory data analysis on a provided data set. Your mission is to continue the investigation you began in C2 and perform further EDA on this data with the aim of learning more about the variables. 
#   
# **The goal** is to clean data set and create a visualization.
# <br/>  
# *This activity has 4 parts:*
# 
# **Part 1:** Imports, links, and loading
# 
# **Part 2:** Data Exploration
# *   Data cleaning
# 
# 
# **Part 3:** Building visualizations
# 
# **Part 4:** Evaluate and share results
# 
# <br/> 
# Follow the instructions and answer the questions below to complete the activity. Then, you will complete an Executive Summary using the questions listed on the PACE Strategy Document.
# 
# Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work. 
# 
# 

# # **Visualize a story in Tableau and Python**

# # **PACE stages** 
# 
# 
# <img src="images/Pace.png" width="100" height="100" align=left>
# 
#    *        [Plan](#scrollTo=psz51YkZVwtN&line=3&uniqifier=1)
#    *        [Analyze](#scrollTo=mA7Mz_SnI8km&line=4&uniqifier=1)
#    *        [Construct](#scrollTo=Lca9c8XON8lc&line=2&uniqifier=1)
#    *        [Execute](#scrollTo=401PgchTPr4E&line=2&uniqifier=1)

# Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute.

# <img src="images/Plan.png" width="100" height="100" align=left>
# 
# 
# ## PACE: Plan 
# 
# In this stage, consider the following questions where applicable to complete your code response:
# 1. Identify any outliers: 
# 
# 
# *   What methods are best for identifying outliers?
# *   How do you make the decision to keep or exclude outliers from any future models?
# 
# 

# ==> ENTER YOUR RESPONSE HERE
# Using code to show max and min values and plotting points are quick ways to identify outliers. Comparing mean and median can tell you which way potential outliers may exist.
# The outlier has to be identified and classified based on its type, then considered in context as to if it will add or detract value from analysis.

# ### Task 1. Imports, links, and loading
# Go to Tableau Public
# The following link will help you complete this activity. Keep Tableau Public open as you proceed to the next steps. 
# 
# Link to supporting materials: 
# Tableau Public: https://public.tableau.com/s/ 
# 
# For EDA of the data, import the data and packages that would be most helpful, such as pandas, numpy and matplotlib. 
# 

# In[21]:


# Import packages and libraries
#==> ENTER YOUR CODE HERE
import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt


# **Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions.

# In[22]:


# Load dataset into dataframe
df = pd.read_csv('2017_Yellow_Taxi_Trip_Data.csv')


# <img src="images/Analyze.png" width="100" height="100" align=left>
# 
# ## PACE: Analyze 
# 
# Consider the questions in your PACE Strategy Document to reflect on the Analyze stage.

# ### Task 2a. Data exploration and cleaning
# 
# Decide which columns are applicable
# 
# The first step is to assess your data. Check the Data Source page on Tableau Public to get a sense of the size, shape and makeup of the data set. Then answer these questions to yourself: 
# 
# Given our scenario, which data columns are most applicable? 
# Which data columns can I eliminate, knowing they won’t solve our problem scenario? 
# 
# Consider functions that help you understand and structure the data. 
# 
# *    head()
# *    describe()
# *    info()
# *    groupby()
# *    sortby()
# 
# What do you do about missing data (if any)? 
# 
# Are there data outliers? What are they and how might you handle them? 
# 
# What do the distributions of your variables tell you about the question you're asking or the problem you're trying to solve?
# 
# 
# 

# -Missing data will be addressed by determining if it will make an impact on analysis first. If it will and there is a lot, consider contacting the data owner to get data filled in. If it is just a few observations or values, see if forward or backfilling will work. Possibly add NaN column if those methods fail. Otherwise, simply remove those rows or columns if there are a small amount of missing values.
# -There are data outliers, and depending on their contect they may need to be removed or excluded from analysis to avoid bias. There are outliers in total amount, fare amount, tip amount, and possibly trip distance.
# -The distributions of data indicate the variables that have insight within them capable of predicting fare amount before the ride has taken place are pickup and dropoff datetime, trip distance, passenger count, fare amount, tip amount and total amount.

# Start by discovering, using head and size. 

# In[23]:


df.head()


# In[24]:


df.shape


# Use describe... 

# In[25]:


df.describe()


# And info. 

# In[26]:


#==> ENTER YOUR CODE HERE
df.info()


# ### Task 2b. Assess whether dimensions and measures are correct

# On the data source page in Tableau, double check the data types for the applicable columns you selected on the previous step. Pay close attention to the dimensions and measures to assure they are correct. 
# 
# In Python, consider the data types of the columns. *Consider:* Do they make sense? 

# Review the link provided in the previous activity instructions to create the required Tableau visualization. 

# ### Task 2c. Select visualization type(s)

# Select data visualization types that will help you understand and explain the data.
# 
# Now that you know which data columns you’ll use, it is time to decide which data visualization makes the most sense for EDA of the TLC dataset. What type of data visualization(s) would be most helpful? 
# 
# * Line graph
# * Bar chart
# * Box plot
# * Histogram
# * Heat map
# * Scatter plot
# * A geographic map
# 

# ==> ENTER YOUR RESPONSE HERE
# bar chart, box plot, histogram
# 

# <img src="images/Construct.png" width="100" height="100" align=left>
# 
# ## PACE: Construct 
# 
# Consider the questions in your PACE Strategy Document to reflect on the Construct stage.

# ### Task 3. Data visualization
# 
# You’ve assessed your data, and decided on which data variables are most applicable. It’s time to plot your visualization(s)!
# 

# ### Boxplots

# Perform a check for outliers on relevant columns such as trip distance and trip duration. Remember, some of the best ways to identify the presence of outliers in data are box plots and histograms. 
# 
# **Note:** Remember to convert your date columns to datetime in order to derive total trip duration.  

# In[27]:


# Convert data columns to datetime
#==> ENTER YOUR CODE HERE
df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])
df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])


# **trip distance**

# In[28]:


# Create box plot of trip_distance
#==> ENTER YOUR CODE HERE
plt.figure(figsize = (20, 10))
sns.boxplot(x = df['trip_distance'],
           fliersize=3)
plt.title('Distribution of Trip Distance', fontsize = 20)
plt.xlabel('Distance in miles', fontsize = 16)
plt.show()


# While the vast majority of rides are under 6 miles, there are a large number of outliers for trips longer than 6 miles.

# In[29]:


# Create histogram of trip_distance
#==> ENTER YOUR CODE HERE
plt.figure(figsize = (20, 10))
sns.histplot(x = df['trip_distance'],
            binrange = [0, 25],
            binwidth = 1)
plt.title('Distribution of Trip Distance', fontsize=20)
plt.xlabel('Distance in miles', fontsize=16)
plt.ylabel('Number of Trips', fontsize=16)
plt.show()


# The vast majority of rides are between 0-3 miles.

# **total amount**

# In[30]:


# Create box plot of total_amount
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20,10))
sns.boxplot(x = df['total_amount'])
plt.title('Distribution of Total Revenue per Trip', fontsize=20)
plt.xlabel('Revenue in dollars', fontsize=16)
plt.show()


# In[31]:


# Create histogram of total_amount
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20,10))
ax=sns.histplot(df['total_amount'],
            binrange = [0, 90],
            binwidth = 5)
ax.set_xticks(range(0,101,5))
plt.xlabel('Revenue in dollars', fontsize=16)
plt.ylabel('Number of trips', fontsize=16)
plt.title('Number of Trips by Total Revenue', fontsize=20)
plt.show()


# Most trips(15k) earn 5-15 dollars while a respectable amount of trips(4.5k) earn 15-25 dollars. 

# **tip amount**

# In[32]:


# Create box plot of tip_amount
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20, 8))
sns.boxplot(x=df['tip_amount'],
             fliersize=3)
plt.xlabel('Tip amount in dollars', fontsize=16)
plt.show()


# In[33]:


df['tip_amount'].value_counts()


# In[34]:


# Create histogram of tip_amount
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20,8))
sns.histplot(x = df['tip_amount'],
            binrange = [0, 15],
            binwidth = 0.5)
plt.title('Distribution of tip amounts', fontsize=20)
plt.xlabel('Tip amount in dollars', fontsize=16)
plt.ylabel('Number of tips', fontsize=16)
plt.show()


# There are 8000 trips with no tip, which is the largest value for this variable, and the range of 1 - 2.50 makes up the majority of tip amounts.

# **tip_amount by vendor**

# In[35]:


#histogram of tip_amount by vendor
plt.figure(figsize=(20,8))
sns.histplot(data=df,
            x=df['tip_amount'],
            hue=df['VendorID'],
            binrange=[0,20],
            binwidth=1,
            multiple='stack',
            palette='pastel')
plt.title('Distribution of tip amounts by vendor', fontsize=20)
plt.xlabel('Tip amount in dollars', fontsize=16)
plt.ylabel('Number of tips', fontsize=16)
plt.show()


# Tips look to be evenly distributed between vendors when looking at all dollar amounts.

# Next, zoom in on the upper end of the range of tips to check whether vendor one gets noticeably more of the most generous tips.

# In[36]:


# Create histogram of tip_amount by vendor for tips > $10 
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20,8))
sns.histplot(data=df,
            x=df['tip_amount'],
            hue=df['VendorID'],
            binrange=[10,25],
            binwidth=0.5,
            multiple='stack')
plt.title('Distribution of tip amounts by vendor', fontsize=20)
plt.xlabel('Tip amount in dollars', fontsize=16)
plt.ylabel('Number of tips', fontsize=16)
plt.show()


# Vendor 2 receives a greater proportion of the high dollar($10+) tips.

# **Mean tips by passenger count**
# 
# Examine the unique values in the `passenger_count` column.

# In[37]:


#==> ENTER YOUR CODE HERE
df['passenger_count'].value_counts()


# one and two passengers make up the bulk of trips, but groups with odd numbers of passengers are more frequent than groups with even numbers of passengers. Perhaps there is a social dynamic where odd groups of people are preferred over even groups of people, when single pupils or friends gather. I assume couples and groups of couples as well as families tend to use their own transportation.

# In[38]:


# Calculate mean tips by passenger_count
#==> ENTER YOUR CODE HERE
df_meantips_passengers = df.groupby('passenger_count')['tip_amount'].mean().reset_index().rename(columns={'tip_amount' : 'mean_tip_amount'})
df_meantips_passengers


# In[39]:


# Create bar plot for mean tips by passenger count
#==> ENTER YOUR CODE HERE
data = df_meantips_passengers.tail(-1)
pal = sns.color_palette('bone', len(data))
rank = data['mean_tip_amount'].argsort().argsort()
plt.figure(figsize=(10, 7))
sns.barplot(data = data,
            x = data['passenger_count'],
            y = data['mean_tip_amount'],
            palette = np.array(pal)[rank])
plt.title('Mean tip amount by number of passengers', fontsize=20)
plt.show()


# Mean tip does not differ significantly between passenger count except for groups of 4. Since most rides were with 1-2 passengers, the mean skews toward them. The global mean is $1.84.

# **Create month and day columns**

# In[40]:


# Create a month column
#==> ENTER YOUR CODE HERE
df['month'] = df['tpep_pickup_datetime'].dt.month

# Create a day column
#==> ENTER YOUR CODE HERE
df['day'] = df['tpep_dropoff_datetime'].dt.day
df['weekday'] = df['tpep_dropoff_datetime'].dt.day_name()
df


# **Plot total ride count by month**
# 
# Begin by calculating total ride count by month.

# In[41]:


# Get total number of rides for each month
#==> ENTER YOUR CODE HERE
df_month_rides = df.groupby('month')['VendorID'].count().reset_index().rename(columns={'VendorID':'ride_count'})
df_month_rides


# Reorder the results to put the months in calendar order.

# In[42]:


# Reorder the monthly ride list so months go in order
#==> ENTER YOUR CODE HERE


# In[43]:


# Show the index
#==> ENTER YOUR CODE HERE


# In[44]:


# Create a bar plot of total rides per month
#==> ENTER YOUR CODE HERE
plt.figure(figsize = (12, 7))
sns.barplot(data = df_month_rides,
           x = df_month_rides['month'],
           y = df_month_rides['ride_count'])
plt.title('Number of rides per month in 2017', fontsize = 20)
plt.xlabel('Month', fontsize=15)
plt.ylabel('Number of rides', fontsize=15)
plt.show()


# The most rides occur in January, March-June and October, with the least number of rides occurring in February and July-September.

# **Plot total ride count by day**
# 
# Repeat the above process, but now calculate the total rides by day of the week.

# In[45]:


df_weekday = df.groupby('weekday')['VendorID'].count().reset_index().rename(columns = {'VendorID':'ride_count'})
df_weekday = df_weekday.sort_values('ride_count', ascending=False).reset_index(drop=True)
df_weekday


# In[46]:


# Repeat the above process, this time for rides by day
#==> ENTER YOUR CODE HERE
weekday=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']


# In[47]:


# Create bar plot for ride_count by day of week
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(12, 7))
sns.barplot(data = df_weekday,
           x = df_weekday['weekday'],
           y = df_weekday['ride_count'],
           order = weekday)
plt.title('Number of rides by day of week', fontsize=20)
plt.xlabel('Day of week', fontsize=16)
plt.ylabel('Number of rides', fontsize=16)
plt.show()


# The most rides occur on Wed-Saturday and the fewest rides occur Sunday- Monday.

# In[48]:


# Create a dataframe of rides by day of month
df_day_rides = df.groupby('day')['VendorID'].count().reset_index().rename(columns = {'VendorID':'ride_count'})
df_day_rides


# In[49]:


# Create bar plot for ride count by day of month
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20, 8))
sns.barplot(data = df_day_rides,
           x = df_day_rides['day'],
           y = df_day_rides['ride_count'])
plt.xlabel('Day of month', fontsize=15)
plt.title('Number of rides by day of month', fontsize=20)
plt.show()


# There is no trend throughout days of the month, except for a significant reduction in rides on the 31st.

# **Plot total revenue by day of the week**
# 
# Repeat the above process, but now calculate the total revenue by day of the week.

# In[50]:


df_revenue_weekday = df.groupby('weekday')['total_amount'].sum().reset_index().rename(columns = {'total_amount':'total_revenue'})
df_revenue_weekday.sort_values('total_revenue', ascending = False).reset_index(drop=True)


# In[51]:


# Repeat the process, this time for total revenue by day
#==> ENTER YOUR CODE HERE
df_revenue_day = df.groupby('day')['total_amount'].sum().reset_index().rename(columns = {'total_amount':'total_revenue'})
df_revenue_day = df_revenue_day.sort_values('total_revenue', ascending=False).reset_index(drop=True)
df_revenue_day


# In[52]:


# Create bar plot of total revenue by day of week
plt.figure(figsize=(12, 7))
sns.barplot(data = df_revenue_weekday,
           x = df_revenue_weekday['weekday'],
           y = df_revenue_weekday['total_revenue'],
           order=weekday)
plt.title('Total revenue by day of week in 2017', fontsize=20)
plt.xlabel('Day of week', fontsize=15)
plt.ylabel('Revenue (USD)', fontsize=15)
plt.show()


# Thursday brings in the highest amount of revenue, with Friday and Wednesday following. Sunday has the lowest revenue, increasing to Thursday, then decreasing again back to Sunday.

# In[53]:


# Create bar plot of total revenue by day of month
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20, 8))
sns.barplot(data = df_revenue_day,
           x = df_revenue_day['day'],
           y = df_revenue_day['total_revenue'])
plt.title('Total revenue by day of month in 2017', fontsize=20)
plt.xlabel('Day of month', fontsize=15)
plt.ylabel('Revenue (USD)', fontsize=15)
plt.show()


# The lowest day of revenue is the 31st.

# **Plot total revenue by month**

# In[54]:


# Repeat the process, this time for total revenue by month
#==> ENTER YOUR CODE HERE
df_revenue_month = df.groupby('month')['total_amount'].sum().reset_index().rename(columns = {'total_amount':'total_revenue'})
df_revenue_month = df_revenue_month.sort_values('total_revenue', ascending=False).reset_index(drop=True)
df_revenue_month


# In[55]:


# Create a bar plot of total revenue by month
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(12, 7))
sns.barplot(data = df_revenue_month,
           x = df_revenue_month['month'],
           y = df_revenue_month['total_revenue'])
plt.title('Total revenue by month in 2017', fontsize=20)
plt.xlabel('Month', fontsize=15)
plt.ylabel('Revenue (USD)', fontsize=15)
plt.show()


# Revenue is the lowest July-Sep and February, and highest in the March-June.

# #### Scatter plot

# You can create a scatterplot in Tableau Public, which can be easier to manipulate and present. If you'd like step by step instructions, you can review the following link. Those instructions create a scatterplot showing the relationship between total_amount and trip_distance. Consider adding the Tableau visualization to your executive summary, and adding key insights from your findings on those two variables.

# [Tableau visualization guidelines](https://docs.google.com/document/d/1pcfUlttD2Y_a9A4VrKPzikZWCAfFLsBAhuKuomjcUjA/template/preview)

# **Plot mean trip distance by drop-off location**

# In[56]:


# Get number of unique drop-off location IDs
#==> ENTER YOUR CODE HERE
df['DOLocationID'].value_counts()


# In[57]:


# Calculate the mean trip distance for each drop-off location
#==> ENTER YOUR CODE HERE
df_dropoff = df.groupby(df['DOLocationID'])['trip_distance'].mean().reset_index().rename(columns={'trip_distance':'mean_trip_distance'})
# Sort the results in descending order by mean trip distance
#==> ENTER YOUR CODE HERE
df_dropoff_sorted = df_dropoff.sort_values('mean_trip_distance', ascending = False).reset_index(drop=True)
df_dropoff_sorted


# In[58]:


# Create a bar plot of mean trip distances by drop-off location in ascending order by distance
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(20, 10))
sns.barplot(data = df_dropoff_sorted,
           x = df_dropoff_sorted['DOLocationID'],
           y = df_dropoff_sorted['mean_trip_distance'],
           order = df_dropoff_sorted['DOLocationID'])
plt.xticks([])
plt.title('Mean trip distance by dropoff location', fontsize=20)
plt.ylabel('Mean trip distance (miles)', fontsize=15)
plt.show()


# ## BONUS CONTENT
# 
# To confirm your conclusion, consider the following experiment:
# 1. Create a sample of coordinates from a normal distribution&mdash;in this case 1,500 pairs of points from a normal distribution with a mean of 10 and a standard deviation of 5
# 2. Calculate the distance between each pair of coordinates 
# 3. Group the coordinates by endpoint and calculate the mean distance between that endpoint and all other points it was paired with
# 4. Plot the mean distance for each unique endpoint

# In[59]:


#BONUS CONTENT

#1. Generate random points on a 2D plane from a normal distribution
#==> ENTER YOUR CODE HERE
test = np.round(np.random.normal(10, 5, (3000, 2)), 1) 
midway = int(len(test)/2)
start = test[:midway]
end = test[midway:]

# 2. Calculate Euclidean distances between points in first half and second half of array
#==> ENTER YOUR CODE HERE
distances = (start - end)**2
distances = distances.sum(axis=-1)
distances = np.sqrt(distances)

# 3. Group the coordinates by "drop-off location", compute mean distance
#==> ENTER YOUR CODE HERE
test_df = pd.DataFrame({'start': [tuple(x) for x in start.tolist()],
                       'end' : [tuple(x) for x in end.tolist()],
                       'distance': distances})
data = test_df[['end', 'distance']].groupby('end').mean()
data = data.sort_values(by='distance')

# 4. Plot the mean distance between each endpoint ("drop-off location") and all points it connected to
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(14, 6))
ax = sns.barplot(x=data.index,
                y=data['distance'],
                order=data.index)
ax.set_xticklabels([])
ax.set_xticks([])
ax.set_xlabel('Endpoint')
ax.set_ylabel('Mean distance to all other points')
ax.set_title('Mean distance between points taken randomly from normal distribution');


# **Histogram of rides by drop-off location**

# First, check to whether the drop-off locations IDs are consecutively numbered. For instance, does it go 1, 2, 3, 4..., or are some numbers missing (e.g., 1, 3, 4...). If numbers aren't all consecutive, the histogram will look like some locations have very few or no rides when in reality there's no bar because there's no location. 

# In[60]:


# Check if all drop-off locations are consecutively numbered
#==> ENTER YOUR CODE HERE
unique_dropoff = set(df['DOLocationID'])
unique_dropoff


# To eliminate the spaces in the historgram that these missing numbers would create, sort the unique drop-off location values, then convert them to strings. This will make the histplot function display all bars directly next to each other. 

# In[61]:


#==> ENTER YOUR CODE HERE
# DOLocationID column is numeric, so sort in ascending order
df_dropoff_sorted = df['DOLocationID'].sort_values()

#==> ENTER YOUR CODE HERE


# Convert to string
#==> ENTER YOUR CODE HERE
df_dropoff_sorted = df_dropoff_sorted.astype('str')

# Plot
#==> ENTER YOUR CODE HERE
plt.figure(figsize=(12,7))
sns.histplot(data=df_dropoff_sorted)
plt.xticks([])
plt.title('Number of rides by dropoff location ID', fontsize=20)
plt.show()
df_dropoff_sorted


# <img src="images/Execute.png" width="100" height="100" align=left>
# 
# ## PACE: Execute 
# 
# Consider the questions in your PACE Strategy Document to reflect on the Execute stage.

# ### Task 4a. Results and evaluation
# 
# Having built visualizations in Tableau and in Python, what have you learned about the dataset? What other questions have your visualizations uncovered that you should pursue? 
# 
# ***Pro tip:*** Put yourself in your client's perspective, what would they want to know? 
# 
# Use the following code fields to pursue any additional EDA based on the visualizations you've already plotted. Also use the space to make sure your visualizations are clean, easily understandable, and accessible. 
# 
# ***Ask yourself:*** Did you consider color, contrast, emphasis, and labeling?
# 
# 

# ==> ENTER YOUR RESPONSE HERE
# 
# I have learned .... 
# There is a small amount of variance in the majority of ride distances, tips and revenue. There are many outliers for distance and total amount.
# 
# My other questions are .... 
# Why are there trips with no passengers? Are those extreme outliers legitimate? Will this data suffice for the model?
# 
# 
# My client would likely want to know ... 
# The range of ride distances, total amounts, the correlation between these two, and the presence of date/time columns, which will allow us to calculate ride duration.

# In[62]:


#==> ENTER YOUR CODE HERE


# In[63]:


#==> ENTER YOUR CODE HERE


# ### Task 4b. Conclusion
# *Make it professional and presentable*
# 
# You have visualized the data you need to share with the director now. Remember, the goal of a data visualization is for an audience member to glean the information on the chart in mere seconds.
# 
# *Questions to ask yourself for reflection:*
# Why is it important to conduct Exploratory Data Analysis? Why are the data visualizations provided in this notebook useful?
# 

# 
# EDA is important because ... 
# ==> ENTER YOUR RESPONSE HERE
# it uncovers the story the data has to tell. It reveals actionable insights that inform business strategy and direction. It allows a professional to intimately know the details behind behaviors and to extract value from those behaviors and correlations.
# 
# Visualizations helped me understand ..
# ==> ENTER YOUR RESPONSE HERE
# relationships between variables of the dataset. It allows rapid comprehension of the relationships and correlations between variables which help a person understand the insight a dataset has to offer, and to know the data's story.

# You’ve now completed professional data visualizations according to a business need. Well done! 

# **Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the "save" icon at the top of this notebook to ensure your work has been logged.
